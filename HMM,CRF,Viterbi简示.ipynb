{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单HMM\n",
    "给出序列和隐状态序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T02:50:55.228091Z",
     "start_time": "2019-07-02T02:50:40.390905Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理词库\n",
    "brown_tags_words = [ ]\n",
    "for sent in brown.tagged_sents():\n",
    "    # 先加开头\n",
    "    brown_tags_words.append( (\"START\", \"START\") )\n",
    "    # 把tag都省略成前两个字母，可不加\n",
    "    brown_tags_words.extend([ (tag[:2], word) for (word, tag) in sent ])\n",
    "    # 加个结尾\n",
    "    brown_tags_words.append( (\"END\", \"END\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'START'),\n",
       " ('AT', 'The'),\n",
       " ('NP', 'Fulton'),\n",
       " ('NN', 'County'),\n",
       " ('JJ', 'Grand'),\n",
       " ('NN', 'Jury'),\n",
       " ('VB', 'said'),\n",
       " ('NR', 'Friday'),\n",
       " ('AT', 'an'),\n",
       " ('NN', 'investigation'),\n",
       " ('IN', 'of'),\n",
       " ('NP', \"Atlanta's\"),\n",
       " ('JJ', 'recent'),\n",
       " ('NN', 'primary'),\n",
       " ('NN', 'election'),\n",
       " ('VB', 'produced'),\n",
       " ('``', '``'),\n",
       " ('AT', 'no'),\n",
       " ('NN', 'evidence'),\n",
       " (\"''\", \"''\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tags_words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK中的CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(wi | ti) = count(wi, ti) / count(ti)\n",
    "\n",
    "# conditional frequency distribution\n",
    "cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# conditional probability distribution\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjective (JJ) being 'new' is 0.01472344917632025\n",
      "The probability of a verb (VB) being 'duck' is 6.042713350943527e-05\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"The probability of an adjective (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
    "print(\"The probability of a verb (VB) being 'duck' is\", cpd_tagwords[\"VB\"].prob(\"duck\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(ti | t{i-1}) = count(t{i-1}, ti) / count(t{i-1})\n",
    "\n",
    "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
    "\n",
    "# bigram的意思是 前后两个一组，联在一起\n",
    "cfd_tags = nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "# P(ti | t{i-1})\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we have just seen 'DT', the probability of 'NN' is 0.5057722522030194\n",
      "If we have just seen 'VB', the probability of 'JJ' is 0.016885067592065053\n",
      "If we have just seen 'VB', the probability of 'NN' is 0.10970977711020183\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"If we have just seen 'DT', the probability of 'NN' is\", cpd_tags[\"DT\"].prob(\"NN\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'JJ' is\", cpd_tags[\"VB\"].prob(\"DT\"))\n",
    "print( \"If we have just seen 'VB', the probability of 'NN' is\", cpd_tags[\"VB\"].prob(\"NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the tag sequence 'START PP VB TO VB END' for 'I want to race' is: 1.0817766461150474e-14\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "prob_tagsequence = cpd_tags[\"START\"].prob(\"PP\") * cpd_tagwords[\"PP\"].prob(\"I\") * \\\n",
    "    cpd_tags[\"PP\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"want\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"TO\") * cpd_tagwords[\"TO\"].prob(\"to\") * \\\n",
    "    cpd_tags[\"TO\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"race\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"END\")\n",
    "\n",
    "print( \"The probability of the tag sequence 'START PP VB TO VB END' for 'I want to race' is:\", prob_tagsequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi 的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们手上有一句话，怎么知道最符合的tag是哪组呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state集合\n",
    "distinct_tags = set(brown_tags)\n",
    "\n",
    "sentence = [\"I\", \"want\", \"to\", \"race\" ]\n",
    "sentlen = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从start开始的初始转移概率\n",
    "def start(tag):\n",
    "    return cpd_tags[\"START\"].prob(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转移概率\n",
    "# trans_p = {}\n",
    "# for i in distinct_tags:\n",
    "#     trans_p[i] = {j: cpd_tags[i].prob(j) for j in distinct_tags}\n",
    "# print(trans_p)\n",
    "def trans(lasttag, curtag):\n",
    "    return cpd_tags[lasttag].prob(curtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 释放概率\n",
    "def emission(tag, word):\n",
    "    return cpd_tagwords[tag].prob(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(sentence, states):\n",
    "    # path[s] 以s结尾的path\n",
    "    path = {s:[] for s in states}\n",
    "    # 当前step的得分\n",
    "    cur_score = {}\n",
    "    \n",
    "    # 从“START”到sentence[0]的得分\n",
    "    for s in states:\n",
    "        cur_score[s] = start(s) * emission(s, sentence[0])\n",
    "        \n",
    "    # 由n-1步计算结果，求第n步的所有可能state的得分\n",
    "    for i in range(1, len(sentence)):\n",
    "        word = sentence[i]\n",
    "        last_score = cur_score\n",
    "        cur_score = {}\n",
    "        for cur_state in states:\n",
    "            # 第n步cur_state的最高得分，及对应的前一个state\n",
    "            max_score, last_state = max(((last_score[state]*trans(state, cur_state)*\n",
    "                                          emission(cur_state, word), state) for state in states))\n",
    "            cur_score[cur_state] = max_score\n",
    "            path[cur_state].append(last_state)\n",
    "            # 最后一个step，加上cur_state\n",
    "            if i == len(sentence) - 1:\n",
    "                path[cur_state].append(cur_state)\n",
    "    \n",
    "    # 以最大的'END'结束状态序列为结果\n",
    "    max_p, prev_state = max(((cur_score[s]*trans(s, 'END'), s) for s in states))\n",
    "    max_path = path[prev_state]\n",
    "\n",
    "    # 根据最后一个时刻的max_p，选择path，未考虑'END'的情况\n",
    "    # 对应路线，由path字典全纪录(Dynamic Programming)\n",
    "    # max_p = 0\n",
    "    # max_path = None\n",
    "    # for s in states:\n",
    "    #     if cur_score[s] > max_p:\n",
    "    #         max_path = path[s]\n",
    "    #         max_p = cur_score[s]\n",
    "\n",
    "    return max_path, max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['PP', '``', 'IN', 'NN'], 5.71772824864617e-14)\n"
     ]
    }
   ],
   "source": [
    "print(viterbi_decode(sentence, distinct_tags))  # 训练语料有限"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
